#+TITLE: 005 Configuration Management And The Cloud

* Week 1: Automating with Configuration Management
** Course Introduction
*** Course Introduction
In this course we will learn:
- How to apply automation to manage fleets of computers
- How to automate deploying new computes
- How to keep machines updated
- How to manage large-scale changes
- And more.

Both for physical machines and virtual machines on the cloud.

What is SRE?
    Site Reliability Engineering is focused in the reliability and maintainability of large systems. In the process, apply a lot of automation to manage them.

Configuration management: lets us manage the configuration of our computers at scale.
** Introduction to Automation at Scale
*** Introduction to Module 1: Automating with Configuration Management
*** What is Scale?
Being able to *scale* what we do means that we can keep achieving larger impacts with the same amount of effort. In short, a scalable service is a flexible one.

Adding more computers can be easy or really hard, depending on how the infrastructure is set up.

Automation is an essential tool for keeping up with the infrastructure needs of a growing business.
*** What is Configuration Management?
E.g. imagine you want to add a new server, manually setting it up is called unmanaged configuration (OS, applications, configuration files, policies, etc... ).

Managed configuration means using a configuration management system to manage all the computers in the fleet, also known as nodes. Typically, you define a set of rules that have to be applied to the nodes you want to manage and then have a process that ensures that those settings are true on each of the nodes.

At a small scale, unmanaged configuration seems inexpensive. However, adding new services can take a lot of time and when things go wrong (which often happens), it can take a lot of time to get back online.

Using a configuration management, the changes you make to a system or a group of systems are done in a systematic, repeatable way. It also makes making changes efficient and consistent.

Configuration management system can handle with some kind of errors by themselves. E.g. if an user changes a configuration file, the configuration management will let you know and will also restore the file to the state before the user changed it.

Examples of configuration managers: Puppet, Chef, Ansible, CFEngine

    These tools can be used to manage locally hosted infrastructure (bare metal such as laptops and virtual machines). Some also are capable of cloud integration (such as AWS EC2, Microsoft Azure, or Google Cloud platform).

    There are also some platform specific tools like SCCM and Group Policy for Windows.

To make the most out of our configuration management system, use the infrastructure as code paradigm.
*** What is infrastructure as code?
When we used a configuration management system, we write rule that describe how the computers in our fleet should be configured. These rules are then executed by the automation, to make the computers match our desired state. This means that we can model the behavior of our IT infrastructure in files that can be processed by automation tools. These files can be tracked in a version control system which is super useful when we need to revert changes.

The paradigm of storing all the configuration for the managed devices in version controlled files is known as infrastructure as code or IaC.

    Infrastructure as code (IaC): When all the configuration necessary to deploy and manage a node in the infrastructure is stored in version control.

The principles of IaC are commonly applied to cloud computing environments where machines are treated like interchangeable resources, instead of individual computers.

Even if there is only one computer, using VCS to track configuration files has advantages such are having the file reviewed by others, rolling back, and quickly set up a new computer if the one in use fails as well as setting up automated tests.

Managing your infrastructure as code means that your fleet of nodes are consistent, versioned, reliable, and repeatable.
** Introduction to Puppet
*** What is Puppet?
Puppet is the current industry standard. It is popular open-source project which is cross platform.

Puppet is usually deployed in a client-server architecture. The client is known as the Puppet Agent and the server is known  as the Puppet Master. The agent sends a list of 'facts' to the Master and the Master then sends a set of 'Rules' that need to be applied to the device.

Example of a Rule:

    class sudo {
        package { 'sudo':
            ensure => present,
            }
    }

This block is saying that the package named 'sudo' has to be present wherever the rule is applied, an if it is not found, then install it.

Puppet will determine the type of OS and use the right tool to install the package. However, for windows, we'll need to add an extra attribute to our rule stating where the installer file is located on the local disk or a network mounted resource or add a an extra 'Chocolately' provider to Puppet.

Puppet can also add, remove, modify configuration files stored on the system  or change registry entries on windows. We can also enable, disable, start, or stop the services that run on our computers.

We can also configure crone jobs or schedule tasks, add, remove, or modify users and groups or even execute external commands.
*** Puppet Resources
Resources: The basic unit for modeling the configuration that we want to manage.

    In other words, each resource specifies one configuration that we are trying to manage (like a service, package, or a file)

File Resource Example 1:

    class sysctl {
        # Make sure the dictionary exists, some distros do not have it
        file { '/etc/sysctl.d':
            ensure => directory
        }
    }

This block ensures that the directory exists.

File Resource Example 2:

    class timezone {
    file { '/etc/timezone':
        ensure => file,
        content => "UTC\n",
        replace => true,
        }
    }

This block configures the file 'timezone'. Here, the resource configuration states the 'timezone' needs to be a file, set the contents of the file to UTC time zone, and set 'replace' to true meaning that if there is an existing file with that name, it will replace the file.

You can also change permissions, file owners, or modification time.

When declaring rules, we are stating the desired state of the resource in the system. The puppet Agent turns this desired state into reality using providers.

The provider used will depend on the resource defined and the environment where the agent is running. Puppet will normally detect this automatically.
*** Puppet Classes
Classes are used to collect the resources that are needed to achieve a goal in a single place. E.g. you could have a class that installs a packages, modifies its configuration file, and starts the service provided by that package.

    E.g. a class with three resources, all related to 'NTP' (Network Time Protocol), the mechanism our computers use to synchronize the clocks.

        class ntp {
            package { 'ntp':
                ensure => latest,
            }
            file { '/etc/ntp.conf':
                source => 'puppet://modules/ntp/ntp.conf'
                replace => true,
                }
            service {'ntp':
                enable => true,
                ensure => running,
                }
        }

    The class ensures that the package is always updated to the latest version, the contents of the configuration file is specified and set to replace any existing file, and to ensure that the service is running.

    By grouping related resources into a single class, we get the advantages of ensuring efficiency and convenience for future changes.
*** puppet docs
https://puppet.com/docs/puppet/7/lang_resources.html
** The Building Blocks of Configuration Management
*** What are domain-specific languages? DSL
java, python, go are general purposes languages.

Domain specific language: A programming language that's more limited in scope.

The DSL in puppet is limited to operations related to when and how to apply configuration management rules. Puppet's DSL includes variables, conditional statements, and functions.

Puppet's facts: variables that represent the characteristics of the system.

    There are many built-in facts into puppet such as facts to store the node OS, IP address, memory available, etc...

    E.g. Facts usage ('smartmontools is a package used for monitoring the state of hard drives using 'smart' command' which does not make sense to have in virtual machines)

        if $facts['is_virtual'] {
            package {'smartmontools':
                ensure => purged,
            }
        } else {
            package{'smartmontools':
                ensure => installed,
            }
        }


        The '$facts' variable is a puppet's DSL hash (which is equivalent to a dictionary in python).
*** The Driving Principles of Configuration Management

Puppet uses as declarative language, because we declare the state that we want to achieve rather than the steps to get there.

Python and C are procedural languages because we write out the procedure that the computer needs to follow to reach our desired goal.

Operations in configuration management should be idempotent. An *idempotent* action can be performed over and over again without changing the system after the first time action was performed, and with no unintended side effects.

    If a script is idempotent, it means it can fail halfway through its task and be run again without problematic consequences.

        Most puppet resources provide idempotent actions.

            A notable exception is the 'exec' resource which runs commands for us and these commands can modify the system each time it is executed. E.g. moving a file, this will only work once and yield a puppet error otherwise. There is a workaround:

                exec { 'move example file':
                    command => 'mv /home/user/example.txt /home/user/Desktop',
                    onlyif => 'test -e /home/user/example.txt'
                }

            This is now a idempotent action because it will only move the file if 'onlyif' is true (i.e. test that the file we are trying to move exists in the directory).


Test and repair paradigm: Meaning that actions are taken only when they are necessary to achieve a goal. For example, only install a package if it hasn't been installed before.

Poppet is stateless, each puppet run is independent of each previous puppet run. Puppet does not save the state between runs of the agents.
*** More Information About Configuration Management
http://radar.oreilly.com/2015/04/the-puppet-design-philosophy.html
*** Assignment qwiklabs
/etc/profile.d/ is a directory used to store scripts which will perform startup tasks, including setting up a user's own environment variables.

PATH variable: environment variable that contains an ordered list of paths that Linux will search for executables when running a command. This is useful because it means we do not have to specify the absolute path for each command we want to run.

    The PATH variable typically contains a few different paths which are separated bY colons.

**** tip
To append a path directory to the PATH environment variable using puppet, you can use

class profile {
    file { '/etc/profile.d/append-path.sh':
        owner => 'root',
        group => 'root',
        mode => '0644',
        content => "PATH=\$PATH:/java/bin\n"
    }
}

To trigger a manual run of the puppet agent by running:
'$ sudo puppet agent -v --test'
* Week 2: Deploying Puppet
** Deploying Puppet Locally
*** Intro to Module 2: Deploying Puppet
We will install puppet locally and set up a test set-up. Also, we'll see how to set up a client-server set-up with puppet clients connecting and authenticating to the Puppet server.
*** Applying rules locally
Puppet is usually deployed in a client-server architecture but that is not the only way we can use puppet. We can use it as a stand alone command line application. This can be the preferred configuration for complex setups where connecting to a master is no longer the best approach.
**** to install puppet
just intall puppet using the OS package manager such as pacman or apt. E.g. '$ sudo pacman -S puppet'
**** Example usage, debugging tools
You can create the most simple file, in this case you want to use ensure that some debugging tools are available at all the nodes. The file that stores this configuration (rules) is called manifest and has extension .pp, for example 'tools.pp'

    Example 'tools.pp':

        package { 'htop':
            ensure => present,
        }

    This file installs htop if it is not installed already. To apply the rules, run:
    '$ sudo puppet apply -v tools.pp'
        The '-v' flag runs puppet in verbose mode so that shows text messages to the terminal.
**** Puppet's catalog
After loading all facts for a computer, the server calculates which rules actually need to be applied. For example, if a packet should only be installed when a certain condition is met, this condition is evaluated on the server side based on the gathered facts.

The catalog is the list of rules that are generated for one specific computer once the server has evaluated all variables, conditionals, and functions.
*** Managing Resource Relationships
Puppet's manifests usually include a bunch of resources that are related to each other. You cannot start a service without the configuration, and you cannot change the configuration without the package installed. Puppet manages this resource relationships.

Example:

    class ntp {
        package { 'ntp':
            ensure => latest,
        }
        file { '/etc/ntp.conf':
            source => '/home/user/ntp.conf',
            replace => true,
            require => Package['ntp'],
            notify => Service['ntp'],
        }
        service{ 'ntp':
            enable => true,
            ensure => running,
            require => File['/etc/ntp.conf'],
        }
    }
    include ntp

In this example, resource types are written in lowercase whereas relationships are written with an uppercase for the first letter of the resource.

We write resource types in lowercase when declaring them, but capitalize them when referring to them from another resource's attribute.

In this example, there is also a call to include 'ntp' at the end of the file. Usually, the class is defined in one file and include it in another one.
*** Organizing Your Puppet Modules
Module: A collection of manifests and associated data.

You want to organzine related the manifests under a sensible topic name. E.g you can have a module dedicated to monitor the computer's health, another for setting up the network stack, and yet another one for configuring a web serving application.

All manifest get stored in a directory called manifests, the rest of the data is stored in different directories depending on what it does. E.g. files such as 'ntp.conf' are stored in the 'files' directory. Another example is the 'templates' directory which stores files that are preprocessed before being copied to the client machines. These templates can include values that get replaced after calculating the manifests, or sections that are only present if certain conditions are valid.
**** Summary
So basically, a module is a directory (within the modules directory) which has a manifest, files, templates, etc directories. In it, there should be a 'init.pp' file in the 'manifest' directory and it should define a class with the same name as the module you are creating. 'init.pp' needs to be present since it is the first file that puppet reads when a module gets included.

Any files that your rules use should be stored in the 'files' directory or if they need to be preprocessed, in the 'templates' directory.

These modules can be shared. They can be installed through the OS package manager like this: (in this case, ubuntu) '$ sudo apt install puppet-module-puppetlabs-apache'

    To include a module from a manifest, you can create a file such as 'webserver.pp' like this:

        include ::apache

    The two columns before the 'apache' lets puppet know that this is a global module named 'apache'.

    Finally, to apply the manifest, use the same command as last time:
        '$ sudo puppet apply -v webserver.pp'

**** tip
use '$ tree modules/' to print the structure of the directory 'modules'
*** More Information About Deploying Puppet Locally
The Puppet language style guide: https://puppet.com/docs/puppet/7/style_guide.html
Installing Puppet Server: https://puppet.com/docs/puppet/7/server/install_from_packages.html
** Deploying Puppet to Clients
*** Puppet Nodes
When managing a lot of computers, you might want to have certain rules apply to all of the computers, and some other rules just to a subset of those computers.

In puppet terminology, a node is any system where we can run a puppet agent (e.g. a physical work station, a server, a virtual machine, or even a network router).

For example, a rule definition for all the nodes:

    node default {
        class { 'sudo': }
        class { 'ntp':
                servers => ['ntp1.example.com', 'ntp2.example.com']
        }
    }

On the other hand, if you want some rules to apply to only certain nodes you can use something like this:

    node webserver.example.com {
        class {'sudo': }
        class { 'ntp':
                servers => ['ntp1.example.com', 'ntp2.example.com']
        }
        class { 'apache': }
    }

In this case, the node is identified using a FQDNs (Fully Qualified Domain Name) which is 'webserver.example.com'.

When a node requests which rules it should apply, puppet will look at the node definitions, figure out which one matches the node's FQDN and then give only those rules.

*Node definition usually happens in the 'site.pp' file*
*** Puppet's Certificate Infrastructure
puppets internal workflow:
1. puppet agent sends 'facts' to the puppet master.
2. The puppet master (server) then processes the manifests, generates the corresponding catalog (rules to be applied to that node).
3. The puppet master then sends it back to the puppet agent (client).
4. The puppet agent applies the changes locally.

How does puppet verify the nodes?
puppet uses public ket infrastructure, or PKI, to establish a secure connection between the server and the clients. There are a bunch of different PKI technologies but puppet uses 'secure socket layer or SSL' (same technology used for encrypting transmissions over HTTPS).

    Basically, all machines have two keys related to each other: private key and public key. The private key is secret, only known by that machine. The public key is shared with other machines involved. The sender uses its private key to sign messages and the receivers use the public key to validate the message.

    How do machines know which keys to trust?

        Certificate Authority (CA) verifies the identity of the machine and then creates a certificate stating that the public key goes with that machine.

        Puppet comes with its own CA but you can also use another CA.

When a puppet agent connects with the puppet master for the first time, the puppet master asks for the certificate (made by the CA) and if it can verify the node's identity, it creates a certificate for that node. This way, when a node picks up this certificate, it knows it can trust that puppet master and that the node can use the certificate to identify itself when requesting a catalog.

Why care about the security?
Puppet rules can hold sensitive information that you do not want it to get into the wrong hands. But also to makes sure that the webserver is actually the webserver and not just a rouge machine with the same name. If you are using puppet for managing tests machines, you can ask puppet to automatically sign all request but you should never do this on real computers with real users.

*Always authenticate your machines*

You can verify the identities of the machines automatically through a script. One way to do this is by copying a unique piece of information into the machines when they get provisioned and then use this pre-shared data as part of the certificate request.
*** Setting up Puppet Clients and Servers
For automatically signing puppet certificate request you can use this:
'$ sudo puppet config --section master set autosign true'
*but only use this when testing, never do this for real computers.* For real computers, you have to manually sign the requests or implement a proper validating script.

On the machine that is going to be a puppet agent node:
1. install puppet
2. run '$ sudo puppet config set server ubuntu.example.com' to set the server.
3. test using '$ sudo puppet agent -v --test'. This runs a test.
   This should create a SSL key, create a certificate request after reading a bunch of info, then shows us the fingerprint of the certificate request.
    This certificate request could be used to verify that the request and the server matches the one generated on the machine.
4. The certificate is generated on the puppet master.
5. The puppet agent stores the certificate locally.
6. The puppet agent retrieves the catalog and applies it.

You need to create a file on the 'production environment' like this: '/etc/puppet/code/environments/production/manifests/site.pp':

    node webserver.exmaple.com {
        class {'apache':}
    }
    node default {}

This is a node definition for the webserver and the default nodes. You can then apply this manifest at the webserver like this:
    From the puppet agent '$ sudo puppet agent -v --test'
        This should install apache and other services.

To keep puppet running constantly on the puppet agent, use systemctl.
    '$ sudo systemctl enable puppet'  This will start the puppet service whenever the computer starts up.
    '$ sudo systemctl start puppet' This will start the service now (similar to 'systemctl enable --now puppet')
*** More Information about Deploying Puppet to Clients
Info about SSL on puppet: https://www.masterzen.fr/2010/11/14/puppet-ssl-explained/
** Updating Deployments
*** Modifying and Testing Manifests
When changing a 'manifest', puppet applies these changes to the corresponding nodes.

Use the 'puppet parser validate' command that checks that the syntax of the manifest is correct.

Apply the changes using the '--noop' flag (NO OPerations) which simulates what puppet would do without actually doing it. This way, you can take a look at the list of actions that it would take and check that they're exactly what you wanted puppet to do. Another approach is to have a tests machines that are used exclusively for testing out changes. However, this is manual work and prone to mistakes.

You can test the manifest automatically using 'r-spec'. In these tests, we can set the 'facts' involved to the values that we want and check that the catalog comes out the way we wanted.

Here is a test example:

    describe 'gksu', :type => :class do
        let (:facts) { { 'is_virtual' => 'false' } }
        it {should contain_package('gksu').with_ensure('latest')}
    end


We can write a lot of these tests and run them all whenever there is a change to the rules. This ensures that the rules stay valid and that the new changes didn't break the old rules.

To check that the rules have the effect that we want, we can use a set of test machines where we first apply the catalog and then use scripts to check that the machines are behaving correctly.
*** Safely Rolling Out Changes and Validating Them
Even if the test machine works fine, it does not mean that the changes will work correctly on the machines running on production.

Production: The parts of the infrastructure where the service is executed and served to its users.

To roll out changes safely, first run them through a *test environment*. This environment should be one or two machines with the exact same configuration as the production environment.

Puppet allows for environment configurations. This way, you can completely isolate the configuration of a machine that the agent sees. This is not just for the modules on each node but also for the version of the module (e.g. test a newer version of the apache module). You can have a development environment (for IT specialists), a test environment for a specific feature, production environment, etc...

Pushing changes to the production environment at the same time is usually not a good idea. There is almost always a special case that we do not consider and has
the potential to take the machines offline. It is a better idea to roll out the change in small batches.

    You could have machines marked as early adopters or 'canaries'. These canaries are used to detect possible issues before they reach the other computers. If there is a problem, the damage is contain to only a subset of users.

Do not apply six months worth of changes at once. This will make it difficult to debug. Apply changes every one or two weeks.

*** More Information About Updating Deployments
Write puppet tests: https://rspec-puppet.com/tutorial/
Check that your puppet manifest conform to the style guide: http://puppet-lint.com/
** Module Review
Use version control systems to track the changes in the 'infrastructure as code' files.
